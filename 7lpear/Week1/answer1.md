Q1. 모델이 훈련데이터에서의 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁘다면 어떤 문제가 있는 건가요? 해결책 세 가지는 무엇인가요?

A1. 모델이 훈련 데이터에 과적합된 상황일 수 있습니다.
새로운 데이터를 더 추가하여 훈련하거나,
훈련시에 규제를 두거나,
교차 검증을 통하여 리스크를 줄여볼 수 있습니다. 

Q2. 데이터의 불균형한 특성을 고려할 때, StratifiedKFold 교차 검증을 적용하는 과정에서 발생할 수 있는 문제점은 무엇이며, 이를 어떻게 해결할 수 있을까요? 

A2. 특정 클래스의 데이터가 극단적으로 적어서, 여러 그룹으로 나눴을 때 특정 클래스의 데이터가 너무 적을 경우에는 StratifiedKFold를 사용해도 의미가 없을 수 있다?

부족한 클래스의 데이터를 더 가져오자

Q3. 정확도를 분류기의 성능 측정 지표로 선호하지 않는 이유를 작성해주세요. (Precision과 Recall이라는 키워드를 써서 작성해주세요)
 
A3. 정확도는 "True", "False"의 여부로만 판단을 하기 때문에, (실제로) 맞는 경우나 (실제로) 아닌 경우 중 하나에 해당할 확률이 다른 것보다 크고, 동시에 분류기가 그 중 큰 확률에 해당하는 답변을 내놓는 경우 단순하게 정확도 수치가 높게 나올 수 있다.

따라서, 이렇게 실제 분류 결과가 불균형한 데이터셋을 다룰때는 Precision과 Recall이라는 지표를 사용한다.

그 두개가 더 나아서 정확도를 선호하지 않음.

Q4. 경사하강법을 사용하여 모델을 학습할 때, 조기 종료 규제가 무엇을 의미하며, 이 규제가 왜 필요한지에 대해 설명해주세요.(예측오차와 과대적합이라는 키워드를 써서 설명해주세요)
 
A4. 첨에는 훈련 세트와 검증 세트에 대한 예측오차가 모두 줄어듭니다. 그러다 어느 순간부터 검증 오차는 다시 커집니다. 점점 훈련 데이터에 과대적합 되고있다는 말입니다.

그러니 훈련 세트에 대한 예측오차만 뚫어져라 보기보다는, 적당히 진행하다가 검증 오차가 낮을 때가 오면 그 타이밍을 잡아서 딱 끝내버리는게 좋겠습니다.

조기 종료는 검증 오차가 최소가 되는 지점에서 훈련을 꺼버리는 기술입니다.

그래서 조기 종료 규제를 사용합니다.