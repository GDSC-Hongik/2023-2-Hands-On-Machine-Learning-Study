# 케라스를 사용한 인공 신경망 소개

---

# 인공 신경망

- 뉴런 → 인공 신경망(퍼셉트론) → 다층 퍼셉트론(MLP)
- 다층 퍼셉트론
    - 입력 층 + 은닉 층 + 출력 층
    - 은닉 층 여러개 → 심층 신경망(DNN)

# 케라스 사용법

- 데이터셋 다운로드
- 시퀀셜 API로 모델 만들기
- 모델 컴파일
- 모델 훈련 & 평가
- 모델 예측
- 모델 저장 & 복원
- 콜백
    - 최상의 검증 세트에서의 모델을 저장
    - 조기 종료와 비슷한 역할
- 텐서보드 사용

자세한건 코드 참고

# 신경망 파라미터 튜닝

- 튜닝 라이브러리(케라스 튜너) 사용
- 튜닝은 이렇게 하자
    - 은닉 층 관련
        - 아래층 : 저수준 구조
        - 중간층 : 저수준 구조 연결해서 중간수준 구조 모델링
        - 위쪽층 : 중간수준 구조 연결해서 고수준 구조 모델링
    - 뉴런 개수 관련
        - 첫번째 은닉 층의 뉴런 개수를 크게 하자
    - 학습률
        - (보통) 최대 학습률의 절반 정도
    - 옵티마이저
    - 배치 크기
    - 활성화 함수
        - (보통) ReLU
    - 반복 횟수
        - 튜닝할 필요 없음. 대신 조기 종료 사용

# 심층 신경망 훈련

---

# 그레디언트 소실 & 폭주 문제

- 해결 방법
    - 글로럿과 He 초기화
    - 고급 활성화 함수
        - (ReLU 쓰면 된다며 → 죽은 ReLU 문제..)
        - ReLU 함수의 변형 사용
            - LeakyReLU
            - ELU, SELU
            - GELU, Swish, Mish
    - 배치 정규화
        - BatchNormalization 층 추가
    - 그레이디언트 클리핑

# 사전 훈련된 층 재사용

- 전이 학습
- 비지도 사전 훈련

# 고속 옵티마이저

- 모멘텀 최적화
    - (보통) 모멘텀 값으로 0.9 사용
    - 경사 하강법보다 훨씬 빠름
- 네스테로프 가속 경사
- AdaGrad
- Adam
- AdaMax
- Nadam
- AdamW
- 학습률 스케줄링
    - 학습률 처음엔 크게, 갈수록 작게 변경해야 효율적
    - 거듭제곱 기반 스케줄링
    - 지수 기반 스케줄링
    - 구간별 고정 스케줄링
    - 성능 기반 스케줄링
    - 1사이클 스케줄링

# 규제 사용

- L1, L2 규제
- 드롭아웃
- 맥스-노름 규제
