# Question & Answer Set

### Q 1. 모델이 훈련데이터에서의 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁘다면 어떤 문제가 있는 건가요? 해결책 세 가지는 무엇인가요?
### A 1. 모델이 과대적합 되었습니다. 모델을 단순하게 만들기, 데이터 늘리기, 규제 추가하기.

### Q 2. 데이터의 불균형한 특성을 고려할 때, StratifiedKFold 교차 검증을 적용하는 과정에서 발생할 수 있는 문제점은 무엇이며, 이를 어떻게 해결할 수 있을까요? 
### A 2. 데이터가 불균형할 때 StratifiedKfold를 적용하게 되면 데이터의 불균형성은 train/validation 데이터가 가질 수 있습니다. 하지만 데이터의 수가 적은 클래스의 비율이 유지되었다는 것은 train/validation 데이터가 훈련 데이터에 비해 양이 줄어들었으므로 비율의 분모가 크게 줄어들었고 실제 그 클래스의 데이터 수가 학습하기에, 검증하기에 충분하지 않을 수 있습니다. 이 문제는 학습 시에 오버샘플링을 통해 적은 데이터를 임의로 수를 조정하여 학습시켜 해결할 수 있습니다.

### Q 3. 정확도를 분류기의 성능 측정 지표로 선호하지 않는 이유를 작성해주세요. (Precision과 Recall이라는 키워드를 써서 작성해주세요)
### A 3. 정확도는 클래스 사이 불균형이 심한 데이터에서 성능 측정지표로 사용하기 어렵습니다. 모델이 단순히 비율이 높은 데이터로 예측을 하도록 학습될 수 있습니다. 하지만 precision과 recall의 경우에는 클래스에 비율과 관계없이 성능을 평가할 수 있다는 장점이 있습니다.

### Q 4. 경사하강법을 사용하여 모델을 학습할 때, 조기 종료 규제가 무엇을 의미하며, 이 규제가 왜 필요한지에 대해 설명해주세요.(예측오차와 과대적합이라는 키워드를 써서 설명해주세요)
### A 4. 경사하강법은 모델을 훈련시키면서 모델 파라미터를 조정해 나가는데, 이때 학습 데이터에 대한 손실을 최소화하려고 합니다. 그러나 모델이 훈련 데이터에 지나치게 적응하면 새로운 데이터에 대한 일반화 성능이 떨어질 수 있습니다. 이를 방지하기 위해 훈련 데이터 손실이 일정 기준 이하로 떨어지지 않거나 테스트 데이터에 대한 성능이 떨어질 때 학습을 조기에 중단함으로써 모델이 과적합에 빠지는 것을 막습니다.