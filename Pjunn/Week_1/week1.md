# 1장 한눈에 보는 머신러닝

머신러닝이란, 데이터에서 학습하도록 컴퓨터를 프로그래밍하는 과학입니다.

머신러닝이 뛰어난 분야

- 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제
- 전통적인 방법으로는 해결방법이 없는 복잡한 문제
- 유동적인 환경
- 복잡한 문제와 대량의 데이터에서 인사이트 얻기

### 머신러닝 시스템의 종류

훈련 지도 방식

- 지도 학습: 훈련데이터에 레이블이 포함됩니다.
    - 분류: 스팸인지 정상인지, 스팸 필터가 대표적인 예시
    - 회귀: 특성을 통해 타깃의 수치를 예측하는 것
- 비지도 학습: 훈련데이터에 레이블이 없습니다.
    - 군집 알고리즘: 데이터를 그룹으로 묶습니다.
    - 시각화 알고리즘: 데이터가 조직된 구조를 이해하고 패턴을 파악합니다, 이때 데이터 간소화를 위해 차원 축소를 사용하기도 합니다.
    - 이상치 탐지: 훈련시에 대부분 정상 샘플을 만나 이를 인식하도록 훈련합니다. 그 다음 새로운 샘플을 보고 정상 데이터인지 이상치인지 판단 합니다.
    - 특이치 탐지: 훈련 세트에 있는 모든 샘플과 달라보이는 새로운 샘플을 탐지하는 것이 목적입니다. 따라서 감지하고 싶은 샘플을 모두 제거한 데이터가 필요합니다.
- 준(semi)지도 학습: 레이블이 없는 샘플이 많고 레이블된 샘플은 적은 경우 입니다.
    - 지도 학습과 비지도 학습의 조합: 군집 알고리즘으로 비슷한 샘플을 한 그룹으로 모읍니다. 그다음 레이블이 없는 데이터에 클러스터에서 가장 많이 등장하는 레이블을 부여합니다. 전체 데이터셋에 레이블이 부여되면 지도 학습 알고리즘을 사용할 수 있습니다.
    - 예시) 구글 포토 서비스, 일단 사람들이 클러스터링 되어있습니다. 이때 각 사람에 대해 레이블을 제공받는다면 사진에 있는 모든 사람의 레이블을 알수 있고 쉽게 검색이 가능합니다.
- 자기(self) 지도 학습: 레이블이 전혀 없는 데이터셋에서 레이블이 부여된 데이터를 생성합니다.
    - 레이블이 없는 이미지 데이터가 있다면 각 이미지의 일부분을 마스킹하여 모델이 원본이미지를 복원하도록 훈련합니다. 이렇게 훈련된 모델을 손상된 이미지를 복원하거나 사진에서 물체를 삭제할 수 있습니다. 또한 미세 튜닝(파인 튜닝)함으로써 비슷한 다른 태스크에서도 사용할 수 있습니다. 만약 동물 이미지로 학습한 경우 동물이 어떻게 생겼는지 알고 있을 것 입니다. 이때 마지막 단계에서 동물 종류를 예측하도록 모델을 수정합니다. 이를 **전이 학습**(Transfer learning)이라고 합니다.
    - 자기지도학습은 지도학습과 동일한 작업에 초점을 맞추게 됩니다.
- 강화학습: 에이전트를 학습시킬때 환경을 관찰하고 **행동**을 실행하고 결과로 **보상 또는 벌점**을 받습니다. 가장 큰 보상을 받기 위한 전략을 스스로 학습합니다.

배치 학습과 온라인 학습

- 배치학습: 모든 데이터를 사용하여 훈련 시키며 테스트 시에는 더이상 학습하지 않습니다.
    - 시간이 지나면서 모델 부패, 데이터 드리프트(테스트 데이터 분표 변화) 현상이 일어날 수 있습니다.
- 온라인 학습: 데이터를 한개 씩 또는 미니배치단위로 주입하여 훈련시킵니다.
    - 새로운 데이터가 입력되면 계속 학습합니다.

사례 기반 학습과 모델 기반 학습

- 사례 기반 학습: 훈련 샘플을 기억함으로써 학습합니다. 그리고 유사도 측정을 통해 새로운 데이터와 학습한 샘플을 비교하는 식으로 일반화합니다.
- 모델 기반 학습: 샘플로부터 이 샘플들의 모델을 만들어 예측에 사용합니다.

데이터 특성

- 데이터는 충분히 많을수록 머신러닝 알고리즘이 더 잘 작동합니다.
- 훈련 데이터가 일반화 하려는 사례를 대표해야 합니다.
    - 샘플링 잡음(Noise): 데이터가 적어 대표성이 없는 데이터
    - 샘플링 편향(Bias): 데이터가 커도 표본 추출 방법이 잘못되어 대표성이 없는 데이터
- 데이터 정제: 결측치를 보강하거나 이상치를 제외 합니다.
- Garbage in, Garbage out: 훈련 데이터에 관련 있는 특성이 충분해야 시스템이 학습할 수 있습니다.
- 데이터의 크기에 비례하여 모델의 복잡도를 결정해야 합니다.(과소적합, 과대적합)

### 테스트와 검증

훈련 데이터를 훈련 세트와 테스트 세트로 나누는 것부터 시작합니다.

- 홀드아웃 검증(holdout validation): 훈련 세트의 일부를 나누어 검증 세트를 만듭니다. 검증 세트에서 높은 성능을 내는 모델과 하이퍼 파라미터를 선택하고 전체 훈련 세트에 대해서 다시 훈련하여 만들어진 최종 모델을 테스트 세트에서 평가합니다.
- 교차 검증(cross-validation): 검증 세트가 너무 작거나(평가 어려움) 클 때(훈련 세트 데이터 작음) 발생하는 문제를 해결하는 방법입니다. 작은 검증 세트 여러개를 만들고 검증 세트마다 나머지 데이터에서 훈련한 모델을 해당 검증 세트에서 평가합니다. 모든 모델의 평가를 평균하여 성능을 측정합니다. 학습시간이 검증 세트 수에 비례하여 늘어난다는 단점이 있습니다.
- 데이터 불일치 문제: 학습시 사용하는 데이터와 테스트시 사용하는 데이터의 분포가 차이날때 모델이 훈련 세트에 과대적합 되었는지, 아니면 데이터 분포차이에서 오는 성능 하락인지 알아보기 위해서 훈련 세트와 데이터 분포가 비슷한 훈련-개발 세트를 사용하여 검증합니다. 만약 훈련-개발 세트에서 높은 성능을 가진다면 데이터 분포의 차이가 문제점이므로 전처리가 필요할 수 있습니다. 아니라면 훈련 세트에 과대 적합이 문제점이라고 생각할 수 있습니다.

# 2장 머신러닝 프로젝트 처음부터 끝까지

### 테스트 세트 만들기

- stratified sampling: 선택한 계층에 대해서 동일한 비율을 가지도록 훈련데이터를 테스트 데이터로 나누는 것입니다.

### 상관관계 조사하기

- 표준 상관계수(피어슨의 r)를 쉽게 구할수 있다. 각 데이터가 어떠한 선형관계를 가지는 지를 나타냅니다.
    - 1 이라면 강한 양의상관 관계, -1이라면 강한 음의 상관관계 입니다.

### 범주형 특성

- 범주형 특성의 경우 학습에 사용하기 위해서는 텍스트에서 숫자로 인코딩해야합니다. 이때 0,1,2…와 같이 인코딩 하게 된다면 머신러닝 알고리즘이 0과 1의 관계를 0과 3의 관계보다 더 비슷하다고 생각합니다. 카테고리별 관계 없이 단순히 숫자로 표현하기 위해서 원-핫 인코딩을 사용합니다.
- 각 카테고리별 거리가 모두 같다는 특징이 있습니다.

### 특성 스케일

- 각 특성별 스케일이 다르다면 머신러닝 알고리즘이 잘 작동하지 않습니다. 특성의 범위를 같게 만들어주는 방법입니다.
- 정규화: 최솟값을 빼고 최댓값-최솟값으로 나누어 0~1로 변화합니다.
    - 이상치 영향이 크다.
- 표준화: 평균을 빼고 표준편차로 나누어 계산합니다.
    - 값을 제한하지 않아 이상치에 영향을 덜 받는다는 특징이 있습니다.
- 꼬리가 두꺼운 특성분포: 먼저 분포를 대칭으로 바꾸고 스케일링을 진행합니다.
    - 멱법칙 분포 처럼 꼬리가 아주 길고 두껍다면 특성을 로그값으로 바꾸어 해결합니다.
    - 버킷타이징: 분포를 거의 동일한 크기의 버킷으로 자르고 특성값을 버킷의 인텍스로 할당합니다. 이를 버킷수로 나누어 0~1로 변환할 수 있습니다.
# 3장 분류

### 성능 측정

- 정확도(Accuracy): 정확한 예측의 비율
    - 불균형한 데이터셋을 다룰때 성능 측성 지표로 선호하지 않는다.
- 오차행렬(Confusion Matrix): 오차 행렬의 행은 실제 클래스를 나타내고 열은 예측한 클래스를 나타냅니다.
    - 정밀도(Precision): 양성 예측의 정확도
    - 재현율(Recall): 정확하게 감지한 양성 샘플의 비율, 민감도라고도 불린다.
    - f1 점수: 정밀도와 재현율의 조화 평균
        - 낮은 값에 더 높은 비중을 두어 점수를 높이기 위해서는 둘다 높아야한다.
- 정밀도/재현율 트레이드 오프: threshold에 따라서 둘의 트레이드오프가 발생한다.
    - threshold가 오르면 정밀도 상승, 재현율 하락
    - threshold가 내려가면 정밀도 하락, 재현율 상승
    - 프로젝트에 따라 원하는 성능을 가지는 임계값을 선택하기 위해서는 재현율에 대한 정밀도 곡선을 그려볼수 있다.
    - 정밀도/재현율 곡선에서 재현율이 증가함에 따라 정밀도가 급격하게 줄어드는 하강점 직전을  트레이드오프로 선택하는 것이 좋다.
- ROC 곡선: 거짓 양성 비율에 대한 진짜 양성 비율의 곡선
    - 민감도(재현율)에 대한 1-특이도 그래프
    - 재현율이 높을수록 거짓 양성 비율(양성으로 잘못예측한 음성 샘플)이 늘어납니다.
    - 곡선 아래의 면전(AUC)을 측정하여 분류기를 비교할 수 있습니다.(완벽한 분류는 1, 완전 랜덤은 0.5)
    - 일반적으로 양성 클래스가 드물거나 거짓 음성보다 거짓 양성이 더 중요할 때 PR곡선을 사용하고 그렇지 않으면 ROC곡선을 사용합니다.

### 다중분류

- OvR(one-vs-the-rest): 클래스 개수가 N일때 이진 분류기 N개를 훈련시켜 점수가 가장 높은 클래스 선택
- OvO(one-vs-one): 클래스 개수가 N일때 이진 분류기 N(N-1)/2개를 훈련시켜 가장 많이 양성이 나온 클래스 선택
- mnist 데이터 셋에서 다중 분류 할때 입력의 스케일을 조정하면 정확도가 오르는 것을 볼수 있다.(데이터 정규화(0~255 → 평균이 0 표준편차가 1)) 데이터 간의 거리를 줄여 스케일의 영향을 줄인다.
- 오차 행렬을 그려 오류를 분석할 수 있고 오류에 집중할때에는 올바른 예측에 대한 가중치를 0으로 설정할수 있다.
- 선형 분류기는 클래스마다 픽셀에 가중치를 할당하고 새로운 이미지에 대해 단순히 픽셀 강도의 가중치 합을 클래스의 점수로 계산합니다. 몇개의 픽셀만 다른 3과 5를 쉽게 혼동합니다. 위쪽 선과 아래쪽 호를 이어주는 작은 직선의 위치를 인식해서 구분합니다. 이부분이 이미지로 학습하는 과정의 간략한 통찰력을 제공한다고 생각합니다.

**cross-validation방법으로 검증한 변경점으로 전체 훈련데이터를 학습하는 것까지 해야한다.**

### 다중 출력 분류

- 이미지 잡음 제거: 다중레이블 각 레이블에 다중 클래스인 문제

# 4장 모델 훈련

### 주요 설명 내용

- 선형 회귀를 훈련시키는 두가지 방법
    - 닫힌 형태의 방정식을 직접 계산
    - 경사하강법을 이용한 최적화
- 다항 회귀
    - 비선형 데이터셋을 훈련 시킬때 사용하는 모델
    - 과대적합 방지 방법(Regularization)
- 대표적인 모델
    - 로지스틱 회귀
    - 소프트맥스 회귀

## 본론

### 선형 회귀

- y = ax + b 형태
    - a, b 는 파라미터, 각각 a는 가중치, b는 편향이라고 부릅니다.
- 선형회귀 식을 벡터 형태로 간단하게 적으면 y = W^T@X 형태
    - X, W 모두 열벡터
- 비용함수: 모델이 훈련데이터에 얼마나 잘 들어맞는지 측정하는 지표
    - 훈련을 통해 MSE(Mean Squared Error)를 최소화 하는 W를 찾는다.

### 비용함수를 최소화 하자

- 해석적인 방법
    - 정규 방정식
    - 사이킷런에서의 유사역행렬을 이용한 방법: 정규 방정식 보다 효율적이며 항상 구할 수 있다.
    - 두 방법 모두 n이 특성 수 라고 할때 계산 복잡도가 O(n^2)이상이다.
    - 당연하지만 예측 계산 복잡도는 샘플 수에 비례한다.(복잡도 O(m))
- 경사하강법: 가중치를 랜덤으로 초기화한 후 비용함수가 감소하는 방향으로 가중치를 업데이트하며 최소값에 수렴할때까지 진행한다.
    - 학습률: 스텝의 크기를 나타내는 하이퍼 파라미터로 가중치 업데이트 정도를 나타냅니다.
    - 배치 경사하강법: 모든 훈련데이터의 그레디언트를 평균하여 업데이트에 사용한다.
    - 확률적 경사하강법: 매 스텝에서 한개의 샘플을 랜덤으로 선택하고 그레디언트를 계산하여 업데이트합니다.
        - 에폭마다 데이터 개수 만큼 랜덤 뽑기 후 그레디언트 계산을 반복합니다.
    - 미니배치 경사하강법: 매 스텝에서 임의의 작은 샘플 세트에 대해 그레디언트를 계산하고 업데이트 합니다.

### 다항 회귀

- 2차 이상의 함수를 예측하기 위해 각 특성의 거듭제곱을 새로운 특성으로 추가한 데이터셋에 선형 모델을 훈련시키는 것입니다.
    - 의문점: PolynomialFeatures에서 degree=2 를 잘 모르겠다.
        - 특성이 하나일때(x) → (x, x^2)만들어줌
        - 특성이 두개일때(a, b) → (a, b, ab, a^2, b^2)만들어줌
- 학습곡선:훈련을 진행하면서 훈련세트와 검증세트에 대해 손실함수 값을 확인하며 현재 모델이 과대적합(훈련세트의 손실과 검증 세트의 손실의 차이가 늘어나거나 크다)인지 과소적합(훈련세트의 손실이 높은데 더이상 줄지 않는다)인지 판단한다.

### 규제가 있는 모델

- 릿지 회귀: l2 노름 규제항을 손실함수에 추가한 선형 회귀
    - 정확히는 l2노름 규제항에 a/m이 곱해진 형태(단, a는 모델을 얼마나 규제할 것인지 조절하는 하이퍼 파라미터)
    - 모델의 가중치가 가능한 작게 유지되도록 합니다.
    - **왜 파라미터가 전역 최적점에 가까워질수로 그레디언트가 작아질까요?**
- 라쏘 회귀: l1 노름 규제항을 손실함수에 추가한 선형 회귀
    - 정확히는 l1 노름 규제항에 2a가 곱해진 형태(단, a는 모델을 얼마나 규제할 것인지 조절하는 하이퍼 파라미터)
    - 특징: 덜 중요한 특성의 가중치를 제거하려고 한다. 즉 희소 모델(0인 특성이 많음)을 만든다.
- 엘라스틱 회귀: 릿지 회귀의 규제항과 라쏘회귀의 규제항을 가중평균하여 규제항에 사용합니다.
- 릿지가 기본으로 만약 몇가지 특성만 유용하다고 생각되면 라쏘나 엘라스틱넷을 사용하라.
- 조기 종료: 검증 오차가 최소값에 도달하면 바로 훈련을 중지하는 규제 방법입니다.
    - 과대 적합을 방지하는 데 효과적입니다.
    - SGD, mini-batch 방법에서는 검증오차가 일정 기간동안 최소값보다 클때 학습을 멈춥니다.(배치 경사하강법에서는 회귀 문제일때 최솟값을 확인 할수 있다.)

### 회귀 알고리즘을 사용한 분류

- 이진 분류: 로지스틱 회귀를 사용합니다.
    - 로짓값을 구하고 시그모이드 함수를 통과하여 0~1 확률값을 얻습니다. 미리 설정한 임계값보다 크다면 양성, 작다면 음성으로 예측합니다.
    - 손실함수: 로그 손실
- 다중 클래스 분류: 소프트맥스 회귀를 사용합니다.
    - 샘플이 주어지면 각 클래스마다 로짓값을 계산하고 소프트 맥스 함수를 통과하여 각 클래스의 확률값을 얻습니다. 확률 값이 가장 큰 클래스를 양성으로 예측하고 나머지를 음성으로 예측합니다.
    - 손실 함수: 크로스 엔트로피 손실