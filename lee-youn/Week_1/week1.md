# 1주차 Summary

생성일: 2023년 12월 17일 오전 1:14
주차: 1주차
깃허브 커밋: No
사람: 윤정 이
완료 여부: 완료

<aside>
📌 **키워드 요약**

</aside>

## **1장.** **한눈에 보는 머신러닝**

---

### 머신러닝이란?

- “머신러닝은 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야다.”
- “어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다.”

### 왜 머신러닝을 사용하는가?

- #자동화와 데이터마이닝!

### 머신러닝 시스템 종류

(⇒ 범주들은 서로 배타적이지 않으며 원하는 대로 연결 가능)

- 훈련 지도 방식
    - 지도 학습 : 훈련 데이터에 레이블 포함됨
        - 분류, 회귀
    - 비지도 학습 : 훈련 데이터에 레이블 없음
        - 계층군집, 시각화, 차원축소(→특성 추출로도 이어짐), 이상치 탐지, 특이치 탐지, 연관규칙학습
    - 준지도 학습 : 데이터 일부만 레이블 포함됨
        - 지도학습 + 비지도학습
    - 자기 지도 학습 : 레이블이 전혀없는 데이터셋 → 레이블이 부여된 데이터셋 생성
        - 주로 분류와 회귀에 초점을 맞춤
- 강화 학습
    - 보상과 벌점, 큰 보상을 얻기 위해 정책이라고 부르는 최상의 전략을 학습
- 배치 학습
    - 오프라인 vs 온라인학습(미니배치)
- 사례기반학습 ⇒ 훈련 샘플 기억해서 학습
- 모델기반학습 ⇒ 샘플들의 모델을 만들어 예측에 사용함

### 나쁜 데이터

- 1) 충분하지 않은 양의 훈련 데이터
- 2) 대표성 없는 훈련 데이터
- 3) 낮은 품질의 데이터 #잡음
- 4) 관련 없는 특성

### 나쁜 모델

- 1) 훈련 데이터 과대적합
- 2) 훈련 데이터 과소적합

### 테스트와 검증

- 훈련 세트와 테스트 세트로 나누기
- 홀드아웃 검증(검증 세트)

## 2**장.** 머신러닝 프로젝트 처음부터 끝까지

---

### 큰 그림 보기

- 문제 정의
- 성능 측정 지표 선택
    - ex) RMSE, MAE
- 가정 검사

### 데이터 가져오기

### 데이터 이해를 위한 탐색과 시각화

### 머신러닝 알고리즘을 위한 데이터 준비

- 특성 스케일의 변환
    - min-max 스케일링
    - 표준화
- 사용자 정의 변환기

### 모델 선택과 훈련

- 교차 검증으로 평가하기
    - k-폴드 교차 검증

### 모델 미세 튜닝

- 그리드 서치
    - 탐색하고자 하는 하이퍼파라미터와 시도해볼 값들을 교차 검증을 사용해 조합 평가
- 랜덤 서치
- 앙상블 방법
    - 최상의 모델을 연결해보는 것

### 론칭, 모니터링, 시스템 유지 보수

## 3**장.** 분류

---

### 이진 분류기

- 두 개의 클래스를 구분

### 교차 검증을 사용한 정확도 측정

- 교차 검증을 사용한 정확도 측정
- k-폴드 교차 검증
    
    훈련세트를 k개의 폴드로 나누고, 평가를 위해 매번 다른 폴드를 떼어놓고 모델을 k번 훈련함
    
- 왜 정확도를 분류기의 성능 측정 지표로 선호하지 않을까?
    - 불균형한 데이터셋을 다룰 때(즉, 어떤 클래스가 다른 것보다 월등히 많은 경우) 더욱 그러함
- 분류기의 성능을 평가하는 더 좋은 방법 : **오차 행렬**

### 오차 행렬

- 모든 A/B쌍에 대해 클래스 A의 샘플이 클래스 B로 분류된 횟수를 세는 것
- 오차 행렬의 행 → 실제 클래스
- 오차 행렬의 열 → 예측한 클래스
    - 음성 클래스 EX) ‘5’아님
        - [’진짜 음성’, ‘거짓 양성’]
    - 양성 클래스 EX) ‘5’맞음
        - [’거짓 음성’, ‘진짜 양성’]

**[오차 행렬보다 더 요약된 지표]**

1. **정밀도**

![Untitled](1%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20Summary%20d6634af0861b4457b8ca20be622f1352/Untitled.png)

(TP는 진짜 양성의 수, FP는 거짓 양성의 수)

⇒ 양성 예측의 정확도

1. **재현율**

![Untitled](1%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20Summary%20d6634af0861b4457b8ca20be622f1352/Untitled%201.png)

(FN은 거짓 음성의 수)

⇒ 분류기가 정확하게 감지한 양성 샘플의 비율(진짜 양성 비율)

1. **F1 점수**

![Untitled](1%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20Summary%20d6634af0861b4457b8ca20be622f1352/Untitled%202.png)

⇒ 정밀도와 재현율의 조화 평균

⇒ F1점수가 높아지려면 재현율과 정밀도 모두 높아야 한다.

### 정밀도/재현율 트레이드오프

- 임곗값을 높이면 정밀도 높아짐, 재현율 줄어듦
- 임곗값을 내리면 정밀도 줄어듦, 재현율 높아짐

### ROC 곡선

- 거짓 양성 비율에 대한 진짜 양성 비율의 곡선
- FPR : 1-진짜 음성 비율
- TNF : 진짜 음성비율(특이도)

⇒ ROC 곡선은 재현율에 대한 1 - 특이도 그래프이다

⇒ 재현율이 높을수록 거짓 양성 비율이 늘어나는 트레이드 오프 있음

### 다중 분류

- 둘 이상의 클래스를 구별
- **OvR 전략** : 이미지를 분류할 때 각 분류기의 결정 점수 중에서 가장 높은 것을 클래스로 선택
    - 대부분의 이진 분류 알고리즘에서는 OvR 선호
- **OvO 전략** : 각 숫자의 조합마다 이진 분류기를 훈련시킴
    - 클래스가 N개라면 분류기는 N*(N-1)/2개가 필요
    - 각 분류기의 훈련에 전체 훈련 세트 중 구별할 두 클래스에 해당하는 샘플만 있으면 됨
- 사이킷런에서 OvO나 OvR을 사용하도록 강제하려면 OneVsOneClassifier나 OneVsRestClassifier를 사용

### 오류 분석

- 각 값을 해당 클래스의 총 이미지 수로 나누어 오차 행렬을 정규화하는 것이 중요
- 오차 행렬은 일반적으로 대칭이 아님
- 그래프에서 백분율 해석하는 방법 주의, 올바른 예측은 제외했다는 점 기억!

### 다중 레이블 분류

- 여러 개의 이진 꼬리표를 출력하는 분류 시스템
- 레이블당 하나의 모델을 학습시키는 것 → 레이블 간의 의존성을 포착하기 어려움

### 다중 출력 분류

- 다중 레이블 분류에서 한 레이블이 다중 클래스가 될 수 있도록 일반화한 것
- ex) 깨끗한 타깃 이미지들을 학습시켜 잡음이 섞인 입력이미지를 깨끗하게 만들

## 4**장.** 모델 훈련

---

### 선형 회귀

- 입력 특성의 가중치 합과 편향이라는 상수를 더해 예측을 만듦
- 선형 회귀 모델을 훈련시키려면 RMSE를 최소화하는 세타를 찾아야 함

### 정규 방정식

- 비용함수를 최소화하는 세타를 찾기 위한 해석적인 방법
- 데이터셋이 작고 잡음이 많을수록 정확한 값을 얻기 힘듦
    - 사이키런 Linear Regression 클래스 ⇒ scipy.linalg.lstsq()함수 기반

- 유사역행렬
    - 특이값 분해라 부르는 표준 행렬 분해 기법을 사용해 계산됨

- 계산 복잡도
    - 역행렬을 계산하는 계산 복잡도 → O(n^2.3) ~ O(n^3)사이
    - 즉, 특정 수가 두 배로 늘어나면 계산 시간이 대략 5,3 ~ 8배로 증가
    - 선형회귀 모델은 약 O(N^2) ⇒ 특성이 2배로 늘어나면 계산시간 4배로 증가
        - 예측 계산 복잡도는 샘플 수와 특성 수에 선형적
        - 예측하려는 샘플 증가시, 걸리는 시간도 거의 2배 증가

### 경사하강법

- 여러 종류의 문제에서 최적의 방법을 찾을 수 있는 일반적인 최적화 알고리즘
- 기본 아이디어 : 비용 함수를 최소화하기 위해 반복해서 파라미터 조정
- 가장 중요한 파라미터 : 스텝의 크기 ⇒ **학습률 하이퍼 파라미터**로 결정!
    - 학습률이 너무 작으면 알고리즘이 수렴하기 위해 반복을 많이 진행해야 하므로 시간 오래 걸림
    - 학습률이 너무 크면 더 큰 값으로 발산하게 만들어 적절한 해법 찾지 못함

### 배치 경사 하강법

- 경사 하강법 구현하려면 비용 함수의 gradient를 계산해야 함
    - 세타가 조금 변경될 때 비용함수가 얼마나 바뀌는지! ⇒ **편도함수**
- 적절한 학습률을 찾기 위해 그리드 서치 사용
- 반복 횟수는 어떻게 정할까?!
    - 벡터의 노름이 어떤 값(허용 오차)보다 작아지면 최소값에 도달한 것이므로 알고리즘 중지

### 확률적 경사 하강법

- 매 스텝에서 한 개의 샘플을 랜덤으로 선택하고 그 하나의 샘플에 대한 그레이디언트를 계
- 확률적(랜덤)이므로 이 알고리즘은 배치 경사 하강법보다 불안
- 시간이 지나면 최솟값에 매우 근점하지만 계속 요동쳐 최솟값에 안착하지 못함
- 확률적 경사 하강법이 배치 경사 하강법보다 전역 최솟값을 찾을 가능성 높음
- **담금질 기법** 알고리즘 : 시작할 때 학습률 크게 하고 점차 작게 줄여서 알고리즘이 전역 최솟값에 도달하게 하기
- **학습 스케줄** : 매 반복에서 학습률 결정하는 함수
- 샘플을 랜덤으로 선택하기 때문에 어떤 샘플은 한 에포크에서 여러 번 선택될 수 있고 어떤 샘플은 전혀 선택되지 못할 수도 있음

### 미니배치 경사 하강법

- **미니배치**라 부르는 임의의 작은 샘플 세트에 대해 그레이디언트 계산
- 확률적 경사 하강법보다 행렬 연산에 최적화된 하드웨어, 특히 gpu를 사용해서 성능 향상 가능
- 적절한 학습 스케줄을 사용하면 최솟값에 도달함

![Untitled](1%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20Summary%20d6634af0861b4457b8ca20be622f1352/Untitled%203.png)

### 다항회귀

- 주어진 데이터가 복잡한 형태일 때, 각 특성의 거듭제곱을 새로운 특성으로 추가하고 이 확장된 특성을 포함한 데이터셋에 선형 모델을 훈련
- 특성이 여러 개일때 다항 회귀는 특성 사이의 관계를 찾을 수 있다

### 학습곡선

- 훈련 데이터에서 성능이 좋지만, 교차 검증 점수가 나쁘다? ⇒ 과대적합
- 둘다 좋지 않다? ⇒ 과소적합

**[편향/분산 트레이드오프]**

- 편향
    - 잘못된 가정으로 인한 것
    - 편향이 큰 모델 ⇒ 훈련 데이터에 과소적합되기 쉬움

- 분산
    - 훈련 데이터에 있는 작은 변동에 모델이 과도하게 민감
    - 자유도가 높은 모델이 높은 분산을 가지기 쉬움 ⇒ 훈련 데이터에 과대적합 경향

- 줄일 수 없는 오차
    - 데이터 자체에 있는 잡음 때문에 발생

⇒ 모델의 복잡도가 커지면 분산 늘나고 편향 줄어듦

⇒ 모델의 복잡도가 줄어들면 편향이 커지고 분산이 작아짐

### 규제가 있는 선형모델

- 과대 적합을 줄이는 좋은 방법은 모델을 규제하는 것!
    - 릿지 회귀
        - 규제가 추가된 선형 회귀 버전
        - 규제항은 훈련하는 동안에만 비용함수에추가됨
    - 라쏘 회귀
        - 가중치 벡터의 노름을 사용
        - 덜 중요한 특성의 가중치를 제거하려고 함
        - 자동으로 특성 선택을 수행하고 희소 모델을 만듦
    - 엘라스틱넷 회귀
        - 릿지 회귀와 라쏘 회귀를 절충한 모델
- 라쏘, 엘라스틱넷 ⇒ 불필요한 특성의 가중치를 0으로 만들어줌

### 조기종료

- 검증 오차가 최솟값에 도달하면 바로 훈련을 중지시키는 것
- 예측 오차가 감소하여 멈추었다가 다시 상승 ⇒ 과대적합되기 시작했다
- 검증 오차가 최소에 도달하는 즉시 훈련을 멈춘다!

### 로지스틱 회귀

- 샘플이 특정 클래스에 속할 확률을 추정하는 데 널리 사용됨
- 선형회귀처럼 바로 결과를 출력하지 않고 결과값의 로지스틱 출력
    - 로지스틱 ⇒ 0과 1 사이의 값을 출력하는 시그모이드 함

### 소프트맥스 회귀

- 여러 개의 이진 분류기를 훈련시켜 연결하지 않고 직접 다중 클래스를 지원하도록 일반화
- 소프트맥스 함수를 적용하여 각 클래스의 확률 추정
- 소프트맥스 회귀 분류기는 추정 확률이 가장 높은 클래스를 선택