# ëŒ€íšŒ íšŒê³ 

## ğŸ“Œë³€ê²½í•œ ì 

---

1. ë°ì´í„° ì‚¬ì´ì¦ˆ ë³€ê²½

```python
IMAGE_SIZE = [224, 224]
GCS_PATH = GCS_DS_PATH + '/tfrecords-jpeg-224x224'
AUTO = tf.data.experimental.AUTOTUNE
```

- DenseNet121 ëª¨ë¸ì´ 224x224 ì‚¬ì´ì¦ˆì˜ ì´ë¯¸ì§€ë¡œ í•™ìŠµë˜ì—ˆê¸° ë•Œë¬¸ì— ì´ì— ë§ì¶° image sizeë¥¼ 224x224ë¡œ ì„ íƒí•˜ì˜€ë‹¤.
- image sizeê°€ ì‘ì„ìˆ˜ë¡ í•™ìŠµ ì†ë„ê°€ ë” ë¹¨ëë‹¤!

1. DenseNet121 ëª¨ë¸ ë³€ê²½, model.trainable = Trueë¡œ ë³€ê²½, ë°°ì¹˜ì •ê·œí™”&ë“œë¡­ ì•„ì›ƒ ë ˆì´ì–´ ì¶”ê°€

```python
EPOCHS = 100

with strategy.scope():
    pretrained_model = tf.keras.applications.densenet.DenseNet121(
        weights='imagenet',
        include_top=False ,
        input_shape=[*IMAGE_SIZE, 3]
    )
    pretrained_model.trainable = True
    
    model = tf.keras.Sequential([
        # To a base pretrained on ImageNet to extract features from images...
        pretrained_model,
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.GlobalAveragePooling2D(),
        tf.keras.layers.Dense(len(CLASSES), activation='softmax')
    ])
```

- ì—¬ëŸ¬ ëª¨ë¸ë“¤ì„ ì‹¤í—˜í•´ë³¸ ê²°ê³¼ DenseNet121 ëª¨ë¸ì´ ê°€ì¥ ì¢‹ê²Œ ë‚˜ì˜´
- model.trainableì„ Trueë¡œ ë°”ê¿¨ì„ ë•Œ, Falseì¼ ë•Œë³´ë‹¤ëŠ” ì²˜ìŒ ì •í™•ë„ê°€ ë‚®ê²Œ í•™ìŠµë˜ì—ˆìœ¼ë‚˜ epochê°€ ì¦ê°€í•  ìˆ˜ë¡ ì •í™•ë„ê°€ ë†’ì•„ì§
- ë°°ì¹˜ ì •ê·œí™”ì™€ ë“œë¡­ì•„ì›ƒì„ ì¶”ê°€í•˜ì˜€ì„ ë•Œ ì •í™•ë„ê°€ ë†’ì•„ì§

1. Learning Rate Schedule ë‚´ ê°’ ë³€ê²½

```python
def exponential_lr(epoch,
                   start_lr = 0.001, min_lr = 0.0001, max_lr = 0.01,
                   rampup_epochs = 30, sustain_epochs = 0,
                   exp_decay = 0.8):
```

- ê¸°ì¡´ start_lrì´ ë„ˆë¬´ ì‘ì•„ 0.001ë¡œ ë³€ê²½
- min_lrì´ 0.001ì¼ ë•ŒëŠ” ì •í™•ë„ê°€ 0.86-0.87 ì´ìƒìœ¼ë¡œ ì˜¬ë¼ê°€ì§€ ì•Šì•„ 0.0001ë¡œ ë‚®ì¶¤
- max_lrë„ ì²˜ìŒì—” 0.05ë¡œ í–ˆìœ¼ë‚˜ ê°’ì´ ë„ˆë¬´ í° ê²ƒ ê°™ì•„ 0.01ë¡œ ë³€ê²½

1. earlyStopping ì¶”ê°€

```python
from tensorflow.keras.callbacks import EarlyStopping

# Define training epochs
EPOCHS = 100
STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE

# Define Early Stopping Callback
early_stopping_callback = EarlyStopping(
    monitor='val_loss',  # Monitor validation loss
    patience=3,            # Number of epochs with no improvement after which training will be stopped
    restore_best_weights=True,  # Restore model weights from the epoch with the best value of the monitored quantity
)

history = model.fit(
    ds_train,
    validation_data=ds_valid,
    epochs=EPOCHS,
    steps_per_epoch=STEPS_PER_EPOCH,
    callbacks=[lr_callback],
)
```

- epochì„ 100ìœ¼ë¡œ ë†“ê³  3ë²ˆ epochê°€ ì§„í–‰ë˜ëŠ” ë™ì•ˆ ê°’ì´ ì¦ê°€í•˜ì§€ ì•Šìœ¼ë©´ ë©ˆì¶”ë„ë¡ ì„¤ì •
- ì´ìƒí•˜ê²Œ ì˜ ì‘ë™ì€ ì•ˆí•˜ê³  ê± 100ë²ˆ í•­ìƒ ë‹¤ ëˆ ë“¯,,?

![Untitled](%E1%84%83%E1%85%A2%E1%84%92%E1%85%AC%20%E1%84%92%E1%85%AC%E1%84%80%E1%85%A9%2031a27a9739c94621894e0304661b3cce/Untitled.png)