# 12장 텐서플로를 사용한 사용자 정의 모델과 훈련

## 12. 1 텐서플로 훑어보기
- 텐서플로 - 구글 브레인 팀 개발
- 딥러닝 라이브러리
- 많은 연산은 커널이라고 부르는 여러 구현을 가진다. 
	- CPU, GPU 또는 TPU 와 같은 특정 장치에 맞추어 만들어졌다. 
	- [[GPU]] - 계산을 작은 단위로 나누어 여러 GPU 스레드에서 병렬로 실행 -> 속도를 극적으로 향상
	- [[TPU]]는 더 빠르다. - 딥런이 연산을 위해 특별하게 설계된 ASIC 칩.
	- 텐서플로 - 방대한 생태계
## 12.2 넘파이처럼 텐서플로 사용하기
- tf.Tensor - 변경이 불가능한 객체
- tf.Variable - 변경이 가능한 객체
- 텐서플로의 여러 데이터 구조
- 연산

## 12.3 사용자 정의 모델과 훈련 알고리즘
### 사용자 정의 손실 함수 만들기
- 평균 제곱 오차: 큰 오차에 너무 과한 벌칙을 가함.
- 평균 절댓값 오차: 이상치에 관대해서 훈련이 수렴되기까지 시간이 걸린다. 
- -> 후버 손실(10장)
- 매개변수를 받을 수 있는 함수 만들기
	- threshold 저장 x.
		- get_config() 메서드 구현

### 활성화 함수, 초기화, 규제, 제한 커스터마이징 하기

![[Pasted image 20240110223606.png]]


```
__call__() 메서드 구현하기.
```


### 사용자 정의 지표
- 손실(ex) 크로스 엔트로피): 경사 하강법에서 모델을 훈련하기 위해 사용.
	- 미분 가능해야하고 그레이디언트가 모든 곳에서 0이 아니어야 한다.
- 지표: 모델을 평가할 때 사용
	- 미분 가능하지 않거나 모든 곳에서 그레이디언트가 0이 아니어도 됨. 
- 스트리밍 지표streaming metric (또는 상태가 있는 지표stateful metric)
	- 배치마다 점진적으로 업데이트
	- tf.keras.metrics.Precision 클래스
- 사용자 정의 스트리밍 지표 - tf.keras.metrics.Metric 클래스 상속

### 사용자 정의 층
- 가중치가 없는 층 - tf.keras.layers.Lambda 층으로 감쌀 수 있다.
- 상태가 있는 층 (가중치를 가진 층) - tf.keras.layers.Layer 상속

### 사용자 정의 모델
1. tf.keras.Model 상속
2. 생성자에서 층과 변수 생성
3. 모델이 해야할 작업을 call() 메서드에 구현

### 모델 구성 요소에 기반한 손실과 지표
모델의 구성 요소 - 은닉 층의 가중치나 활성화 함수

### 자동 미분으로 그레이디언트 계산하기
gradient() 메서드
- 한 번 이상 호출해야 하면 지속 가능한 테이프를 만들고 사용이 끝난 후 테이프를 삭제해 리소스를 해제해야 한다.
- jacobian() 메서드
- tf.stop_gradient() 함수 - 신경망의 일부분에 그레이디언트가 역전파되지 않도록 막아야한다.

### 사용자 정의 훈련 반복
- fit() 메서드
- ![[Pasted image 20240111043746.png]]
- 주의해야 할 점이 많고 그 과정에서 실수하기도 쉽다. 
- 장점은 완전하게 제어할 수 있다.


## 12.4 텐서플로 함수와 그래프
tf.function()
- 텐서플로는 계산 그래프를 최적화한다. 
	- 일반적으로 원본 파이썬 함수보다 훨씬 빠르다.
- XLAaccelerated linear algebra를 사용해  전용 커널을 컴파일하며, 종종 여러 연산을 융합한다.
- 다형성(다양한 매개변수 타입과 크기)을 처리한다.
### 오토그래프와 트레이싱
- 파이썬 함수의 소스 코드를 분석해 제어문을 모두 찾는 것.
	- while, if 같은 메서드가 없기 때문이다.


![[Pasted image 20240111044412.png]]
+) 텐서플로 함수를 사용할 때 따라야 할 여러 규칙
